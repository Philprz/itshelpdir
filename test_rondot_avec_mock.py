# test_rondot_avec_mock.py
# Script de test avanc√© avec simulation des clients de recherche

import os
import asyncio
import logging
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
from unittest.mock import MagicMock, patch
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("test_rondot_mock")

# Pr√©paration des imports avec simulation
# On cr√©e des mocks avant d'importer les modules r√©els
search_factory_mock = MagicMock()
qdrant_client_mock = MagicMock()

# Donn√©es simul√©es pour les tests
MOCK_JIRA_RESULTS = [
    {
        "id": "JIRA-1234",
        "score": 0.92,
        "payload": {
            "source_type": "jira",
            "key": "RONDOT-123",
            "summary": "Probl√®me de configuration ERP",
            "description": "Le client RONDOT signale des probl√®mes avec la configuration de l'ERP",
            "created": "2025-02-10",
            "updated": "2025-02-15",
            "status": "En cours"
        }
    }
]

MOCK_ZENDESK_RESULTS = [
    {
        "id": "ZD-5678",
        "score": 0.88,
        "payload": {
            "source_type": "zendesk",
            "ticket_id": "42",
            "subject": "Support technique RONDOT",
            "description": "Demande d'assistance pour d√©ploiement de mise √† jour",
            "created": "2025-03-01",
            "updated": "2025-03-05",
            "status": "Ouvert"
        }
    }
]

# Cr√©ation d'une classe ResultMock pour simuler les r√©sultats de recherche
class ResultMock:
    def __init__(self, result_dict):
        self.id = result_dict.get("id")
        self.score = result_dict.get("score")
        self.payload = result_dict.get("payload", {})
        self.collection_name = result_dict.get("collection_name", "unknown")
        
    def __repr__(self):
        return f"ResultMock(id={self.id}, score={self.score}, source={self.payload.get('source_type', 'unknown')})"

# Classe pour simuler un client de recherche
class SearchClientMock:
    def __init__(self, name, results):
        self.name = name
        self.mock_results = [ResultMock(r) for r in results]
        logger.info(f"Client simul√© {name} initialis√© avec {len(self.mock_results)} r√©sultats")
    
    async def recherche_intelligente(self, question, client_info=None, date_debut=None, date_fin=None, 
                                    max_results=5, threshold=0.1):
        logger.info(f"Recherche simul√©e dans {self.name} pour: '{question}'")
        if client_info and client_info.get('source') == 'RONDOT':
            logger.info(f"Client RONDOT d√©tect√© dans la recherche {self.name}")
            return self.mock_results
        return []

# Fonction pour configurer le mock de search_factory
def configure_search_factory_mock():
    # Cr√©ation des clients simul√©s
    jira_client = SearchClientMock("jira", MOCK_JIRA_RESULTS)
    zendesk_client = SearchClientMock("zendesk", MOCK_ZENDESK_RESULTS)
    
    # Configuration du mock de get_client pour retourner nos clients simul√©s
    async def mock_get_client(source_type):
        if source_type == "jira":
            return jira_client
        elif source_type == "zendesk":
            return zendesk_client
        else:
            # Pour les autres types, retourner un client vide
            return SearchClientMock(source_type, [])
    
    search_factory_mock.get_client = mock_get_client
    return search_factory_mock

# Application des patches pour la simulation
patches = []

def apply_patches():
    global patches
    # Configurer le mock pour search_factory
    sf_mock = configure_search_factory_mock()
    patches.append(patch("chatbot.search_factory", sf_mock))
    
    # Appliquer tous les patches
    for p in patches:
        p.start()
    logger.info("Patches appliqu√©s avec succ√®s")

def remove_patches():
    global patches
    for p in patches:
        p.stop()
    patches = []
    logger.info("Patches retir√©s")

# Maintenant on peut importer les modules r√©els
apply_patches()
try:
    # Import apr√®s le patching et le chargement des variables d'environnement
    from chatbot import ChatBot
    from gestion_clients import extract_client_name
except Exception as e:
    logger.error(f"Erreur lors de l'import des modules: {e}")
    remove_patches()
    raise

async def test_extract_client():
    print("\n---- Test de extract_client_name ----")
    queries = [
        "Quels sont les derniers tickets RONDOT?",
        "J'ai besoin d'info sur les tickets RONDOT",
        "RONDOT a des probl√®mes",
        "Cherche les tickets du client RONDOT",
        "Recherche tickets rondot",  # en minuscule
        "Ticket ERP RONDOT",  # combinaison avec ERP
        "RONDOT"  # juste le nom
    ]
    
    for query in queries:
        client_name, score, metadata = await extract_client_name(query)
        print(f"Query: '{query}'")
        print(f"  ‚Üí Client: {client_name}, Score: {score}, Metadata: {metadata}\n")

class MockConversation:
    def __init__(self):
        self.id = "test_conv_id"
        self.user_id = "test_user"
        self.context = "{}"

async def test_determine_collections():
    print("\n---- Test de determine_collections ----")
    chatbot = ChatBot(
        openai_key=os.getenv('OPENAI_API_KEY', "mock_key"),
        qdrant_url=os.getenv('QDRANT_URL', "mock_url"),
        qdrant_api_key=os.getenv('QDRANT_API_KEY', "mock_api_key")
    )
    
    test_analyses = [
        {
            "type": "support",
            "query": {
                "original": "Tickets r√©cents pour RONDOT"
            }
        },
        {
            "type": "configuration",
            "query": {
                "original": "Probl√®me ERP avec RONDOT"
            }
        },
        {
            "type": "documentation",
            "query": {
                "original": "Documentation pour client RONDOT"
            }
        },
        {
            "type": "support",
            "query": {
                "original": "Tickets r√©cents non RONDOT"
            }
        }
    ]
    
    for i, analysis in enumerate(test_analyses):
        collections = chatbot.determine_collections(analysis)
        print(f"Analyse {i+1}: '{analysis['query']['original']}'")
        print(f"  ‚Üí Collections: {collections}\n")

async def test_process_web_message():
    print("\n---- Test de process_web_message ----")
    chatbot = ChatBot(
        openai_key=os.getenv('OPENAI_API_KEY', "mock_key"),
        qdrant_url=os.getenv('QDRANT_URL', "mock_url"),
        qdrant_api_key=os.getenv('QDRANT_API_KEY', "mock_api_key")
    )
    
    # Simuler la m√©thode analyze_question
    original_analyze = chatbot.analyze_question
    async def mock_analyze_question(text):
        return {
            "type": "support",
            "search_context": {
                "has_client": True
            },
            "query": {
                "original": text,
                "reformulated": text
            }
        }
    chatbot.analyze_question = mock_analyze_question
    
    test_messages = [
        "Je cherche les derniers tickets de RONDOT",
        "Probl√®mes r√©cents pour le client RONDOT",
        "Ticket ERP RONDOT num√©ro 123",
        "Support technique RONDOT urgent"
    ]
    
    mock_conversation = MockConversation()
    
    try:
        for message in test_messages:
            print(f"\nTest avec message: '{message}'")
            response = await chatbot.process_web_message(
                text=message,
                conversation=mock_conversation,
                user_id="test_user",
                mode="detail"
            )
            
            # Extraction des informations cl√©s de la r√©ponse pour v√©rification
            if isinstance(response, dict):
                print(f"Type de r√©ponse: dict")
                if "text" in response:
                    # Limiter la taille du texte pour l'affichage
                    preview = response["text"][:150] + "..." if len(response["text"]) > 150 else response["text"]
                    print(f"Texte de r√©ponse: {preview}")
                
                if "blocks" in response:
                    print(f"Nombre de blocs: {len(response['blocks'])}")
            else:
                print(f"Type de r√©ponse inattendu: {type(response)}")
    
    finally:
        # Restaurer la m√©thode originale
        chatbot.analyze_question = original_analyze

async def main():
    try:
        print("üß™ Test du correctif RONDOT avec simulation des clients")
        print("====================================================\n")
        
        # Test de la fonction extract_client_name
        await test_extract_client()
        
        # Test de determine_collections
        await test_determine_collections()
        
        # Test de process_web_message
        await test_process_web_message()
        
        print("\n‚úÖ Tests termin√©s avec succ√®s!")
        
    except Exception as e:
        print(f"\n‚ùå Erreur pendant les tests: {str(e)}")
    
    finally:
        # Nettoyer les patches
        remove_patches()

if __name__ == "__main__":
    asyncio.run(main())
